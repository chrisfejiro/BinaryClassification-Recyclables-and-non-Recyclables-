# Waste Classification System

Binary image classification system for recyclable vs non-recyclable waste using MobileNetV2 transfer learning.

**Test Accuracy: 97.31% | AUC-ROC: 0.9960 | Inference: <50ms**
---
## Quick Start
```bash
# Install dependencies
pip install -r requirements.txt

# Split dataset
python scripts/split_dataset.py

# Train model
cd src
python train_and_evaluate.py

# Make predictions
cd ..
python predict.py
```

---

## Installation

### Prerequisites
- Python 3.8+
- 8GB RAM minimum
- Optional: NVIDIA GPU for faster training

### Setup
```bash
# Clone repository
git clone https://github.com/chrisfejiro/BinaryClassification-Recyclables-and-non-Recyclables-.git

# Install dependencies
pip install -r requirements.txt

# Verify installation
python -c "import tensorflow as tf; print('TensorFlow:', tf.__version__)"
```
---
## Dataset Preparation
*Note=The total images used when running the code locally was 34,459.Due to this large upload when pushing to Github ,Github truncated the directory to 1000 files each for both Recyclables and Non-Recyclables. 
### Directory Structure

Place your original dataset in this structure:
```
DatasetFinal/
├── Recyclables/        # 17,677 images
└── Non-Recyclables/    # 16,782 images
```

### Split Dataset
```bash
python scripts/split_dataset.py
```
**Output:**
```
data/
├── train/      # 24,134 images (70%)
├── val/        # 5,156 images (15%)
└── test/       # 5,169 images (15%)
```

**Configuration:**
- Edit `scripts/split_dataset.py` to change split ratios
- Default: 70% train, 15% validation, 15% test
- Stratified splitting maintains class balance
---

## Training

### Basic Training
```bash
cd src
python train_and_evaluate.py
```

**Training Time:**
 ~5 hours

### Training Configuration

Edit `src/train_and_evaluate.py` to modify:
```python
# Architecture
INPUT_SHAPE = (224, 224, 3)
DENSE_UNITS = 128
DROPOUT_RATE = 0.5

# Training Phase 1
BATCH_SIZE = 32
EPOCHS_PHASE1 = 10
LEARNING_RATE_PHASE1 = 0.001

# Training Phase 2
EPOCHS_PHASE2 = 20
LEARNING_RATE_PHASE2 = 0.0001
UNFREEZE_LAYERS = 30
```

### Training Process

**Phase 1: Feature Extraction (Epochs 1-10)**
- Freezes MobileNetV2 base
- Trains only classification head
- Learning rate: 0.001

**Phase 2: Fine-Tuning (Epochs 11-30)**
- Unfreezes last 30 layers
- Fine-tunes entire model
- Learning rate: 0.0001

### Output Files
```
models/
├── model_phase1.h5     # Phase 1 checkpoint
├── best_model.h5       # Best model (use this!)
└── final_model.h5      # Final model state

results/
├── training_curves.png
├── confusion_matrix.png
├── roc_curve.png
└── sample_predictions.png
```
---

## Prediction

### Single Image
```bash
python predict.py
```

Enter image path when prompted:
```
Enter path to waste item image: input_images/test.jpg
```

### Batch Prediction

Place images in `input_images/` folder:
```bash
mkdir input_images
cp path/to/images/*.jpg input_images/
python predict.py
```

The script automatically processes all images in the folder.

### Python API
```python
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image

# Load model
model = load_model('models/best_model.h5')

# Preprocess image
img = image.load_img('test.jpg', target_size=(224, 224))
img_array = image.img_to_array(img) / 255.0
img_array = np.expand_dims(img_array, axis=0)

# Predict
prediction = model.predict(img_array)[0][0]

# Classify
if prediction >= 0.5:
    label = "Recyclable"
    confidence = prediction * 100
else:
    label = "Non-Recyclable"
    confidence = (1 - prediction) * 100

print(f"{label}: {confidence:.2f}%")
```

---

## Code Structure
```

├── data/                       # Generated by split script
│   ├── train/
│   ├── val/
│   └── test/
│
├── DatasetFinal/               # Your original dataset
│   ├── Recyclables/
│   └── Non-Recyclables/
│
├── models/                     # Trained models
│   ├── best_model.h5          Use this for predictions
│   ├── final_model.h5
│   └── model_phase1.h5
│
├── results/                    # Evaluation results
│   ├── confusion_matrix.png
│   ├── roc_curve.png
│   ├── sample_predictions.png
│   └── training_curves.png
│
├── scripts/
│   └── split_dataset.py       # Dataset splitting
│
├── src/
│   └── train_and_evaluate.py  # Training & evaluation
│
├── input_images/               # Test images
├── predict.py                  # Prediction script
├── requirements.txt            # Dependencies
└── README.md                   # This file
```

---

## Model Architecture
```
Input (224×224×3)
    ↓
MobileNetV2 Base (ImageNet weights)
    ↓
GlobalAveragePooling2D
    ↓
Dense(128, ReLU)
    ↓
Dropout(0.5)
    ↓
Dense(1, Sigmoid)
    ↓
Output (0-1 probability)
```

**Model Details:**
- Base: MobileNetV2 pre-trained on ImageNet
- Custom layers: 164,097 parameters
- Total parameters: 2,423,105
- Trainable (Phase 2): 1,251,073
- Model size: 14 MB
---

## Data Augmentation

**Training set only:**
```python
ImageDataGenerator(
    rescale=1./255,
    rotation_range=20,
    width_shift_range=0.1,
    height_shift_range=0.1,
    shear_range=0.1,
    zoom_range=0.2,
    horizontal_flip=True,
    brightness_range=[0.8, 1.2]
)
```

**Validation/Test sets:**
- Only rescaling (1./255)
- No augmentation
---

## Hyperparameters

| Parameter | Value | Description |
|-----------|-------|-------------|
| `INPUT_SHAPE` | (224, 224, 3) | Input image dimensions |
| `BATCH_SIZE` | 32 | Images per batch |
| `DENSE_UNITS` | 128 | Dense layer neurons |
| `DROPOUT_RATE` | 0.5 | Dropout probability |
| `LEARNING_RATE_PHASE1` | 0.001 | Initial learning rate |
| `LEARNING_RATE_PHASE2` | 0.0001 | Fine-tuning learning rate |
| `EPOCHS_PHASE1` | 10 | Feature extraction epochs |
| `EPOCHS_PHASE2` | 20 | Fine-tuning epochs |
| `UNFREEZE_LAYERS` | 30 | Layers to fine-tune |

To modify, edit the hyperparameters section in `src/train_and_evaluate.py`.
---

## Performance

### Test Results
```
Accuracy: 97.31%

Classification Report:
                precision    recall  f1-score   support
Non-Recyclable     0.9681    0.9770    0.9725      2517
Recyclable         0.9779    0.9695    0.9737      2652

Confusion Matrix:
[[2459   58]
 [  81 2571]]

AUC-ROC: 0.9960
```
---

## Troubleshooting

### Common Issues

**Error: `DatasetFinal not found`**
```bash
# Ensure folder exists in project root
ls DatasetFinal
```

**Error: `Out of memory`**
```python
# In src/train_and_evaluate.py, reduce batch size:
BATCH_SIZE = 16  # or 8
```

**Error: `Module not found`**
```bash
# Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

**Training is slow**
```bash
# Check GPU availability
python -c "import tensorflow as tf; print('GPU:', tf.config.list_physical_devices('GPU'))"

# If no GPU, training on CPU takes 3-5 hours (expected)
```

**Low accuracy after training**
- Check dataset quality (corrupted images)
- Verify data split worked correctly
- Ensure sufficient training time (don't interrupt)
- Try increasing epochs in Phase 2

---

## Requirements
```txt
tensorflow==2.14.0
numpy==1.24.3
matplotlib==3.7.2
seaborn==0.12.2
scikit-learn==1.3.0
Pillow==10.0.0
```

**Recommended System Requirements:**
- Python 3.8+
- 8GB RAM minimum (16GB recommended)
- 20GB storage minimum
- Optional: NVIDIA GPU with 4GB+ VRAM

---

## Key Scripts

### 1. `scripts/split_dataset.py`

**Purpose:** Split original dataset into train/val/test

**Usage:**
```bash
python scripts/split_dataset.py
```

**Configuration:**
```python
split_dataset(
    source_dir='DatasetFinal',
    output_dir='data',
    train_ratio=0.70,
    val_ratio=0.15,
    test_ratio=0.15,
    random_seed=42
)
```
---

### 2. `src/train_and_evaluate.py`

**Purpose:** Train model and evaluate performance

**Usage:**
```bash
cd src
python train_and_evaluate.py
```

**What it does:**
1. Loads and augments training data
2. Builds MobileNetV2 model
3. Trains Phase 1 (feature extraction)
4. Trains Phase 2 (fine-tuning)
5. Evaluates on test set
6. Generates visualizations
7. Saves models and results

**Output:**
- `models/best_model.h5`
- `results/*.png`

---

### 3. `predict.py`

**Purpose:** Make predictions on new images

**Usage:**
```bash
python predict.py
```

**What it does:**
1. Loads trained model
2. Scans `input_images/` folder
3. Predicts each image
4. Displays results with confidence

**Example output:**
```
plastic_bottle.jpg: RECYCLABLE (0.9873)
food_waste.jpg: NON-RECYCLABLE (0.9624)
aluminum_can.jpg: RECYCLABLE (0.9912)
```

---

## Customization

### Change Model Architecture

Edit `src/train_and_evaluate.py`:
```python
# Change dense layer size
DENSE_UNITS = 256  # Default: 128

# Change dropout rate
DROPOUT_RATE = 0.3  # Default: 0.5

# Change number of unfrozen layers
UNFREEZE_LAYERS = 50  # Default: 30
```

### Modify Data Augmentation

Edit `src/train_and_evaluate.py`:
```python
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,        # Change from 20
    zoom_range=0.3,           # Change from 0.2
    horizontal_flip=True,
    vertical_flip=True,       # Add vertical flip
    brightness_range=[0.7, 1.3]  # Adjust brightness
)
```

### Change Classification Threshold

Edit `predict.py`:
```python
# Default threshold: 0.5
if prediction >= 0.5:  # Change to 0.6 for higher precision
    label = "RECYCLABLE"
```

---

## Dataset Statistics

| Split | Total | Recyclable | Non-Recyclable |
|-------|-------|------------|----------------|
| Train | 24,134 | 12,374 (51.3%) | 11,747 (48.7%) |
| Val | 5,156 | 2,652 (51.4%) | 2,517 (48.8%) |
| Test | 5,169 | 2,651 (51.3%) | 2,518 (48.7%) |
| **Total** | **34,459** | **17,677** | **16,782** |

---
